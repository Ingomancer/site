+++
date = 2024-04-02T05:26:12Z
draft = false
title = "Kodsnack 576 - Jag ger dig ett svar på måndag, med Vilhelm von Ehrenheim"
slug = "576"
aliases = ["/blog/2024/04/02/576"]
categories = ["avsnitt"]
audiofile = "https://traffic.libsyn.com/kodsnack/576.mp3"
libsynid = "30627198"
english = false
audiosize = "25837251"
audiolength = "53:46"
people = ["Fredrik Björeman", "Vilhelm von Ehrenheim"]
sponsor = []
images = ["avsnitt/576/576-cover.png"]
+++

Fredrik snackar med [Vilhelm von Ehrenheim](https://www.linkedin.com/in/vilhelm-von-ehrenheim/) om teknik som kan tänkas påverka det vi kallar AI framöver. Vilka tekniker är intressanta, och vad innebär de?

Vi diskuterar bland annat:
* Vad innebär kontext för språkmodeller?
* Multimodalitet - kunna resonera om text och bild samtidigt
* Kunskapgrafer och [RAG](https://www.pinecone.io/learn/retrieval-augmented-generation/) - tekniker för att försöka få svar som är "mer rätt" och har mindre risk att verka påhittade inom specifika sammanhang
* Blir det fler stora generella modeller framöver, eller fler små och specialiserade?
* Kunskapsgrafer och sökmotorer. Det pågår mycket utveckling kring att bättre knyta fakta och information från specifika områden - till exempel ditt företags situation just nu - till mer generellt tränade modeller, för att man inte ska behöva specialträna en modell för varje specifikt område, och inte heller behöva träna om varje gång omvärlden förändras
* Agenter - sätt för modeller att interagera med som omgivning och utföra saker
* Resonerande - vad menar man med det? Hur mäter man det? Och inte minst: hur tränar man egentligen modeller för att bli bättre på det?
* Kommer det stora modellerna bli ännu större? Gör mer träningsdata mer nytta?
* Och som avslutning: finns det några andra intressanta approacher som vi inte hör så mycket om för att det stora språkmodellerna just nu får all uppmärksamhet och investeringar?

Ett stort tack till [Cloudnet](https://www.cloudnet.se) som sponsrar vår [VPS](https://en.wikipedia.org/wiki/Virtual_private_server)!

Har du kommentarer, frågor eller tips? Vi är [@kodsnack](https://social.podsnack.se/@kodsnack), [@thieta](https://6510.nu/@thieta), [@krig](https://6510.nu/@krig), och [@bjoreman](https://toot.cafe/@bjoreman) på Mastodon, har en [sida på Facebook](https://www.facebook.com/) och epostas på [info@kodsnack.se](mailto:info@kodsnack.se) om du vill skriva längre. Vi läser allt som skickas.

Gillar du Kodsnack får du hemskt gärna [recensera oss i iTunes](https://itunes.apple.com/se/podcast/kodsnack/id561631498?l=en)! Du kan också stödja podden genom att <a href="https://ko-fi.com/kodsnack" rel="payment">ge oss en kaffe (eller två!) på Ko-fi</a>, eller [handla något i vår butik](https://shop.spreadshirt.se/kodsnack/).

## Länkar ##
* [Vilhelm](https://www.linkedin.com/in/vilhelm-von-ehrenheim/)
* [QA.tech](https://qa.tech/)
* [554 - Tidigare avsnitt med mer om vad QA.tech gör](https://kodsnack.se/554/)
* [Kontext](https://medium.com/@crskilpatrick807/context-windows-the-short-term-memory-of-large-language-models-ab878fc6f9b5) när det gäller språkmodeller
* [Gemini lärde sig ett språk i kontext](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024)
* [Multimodalitet](https://huyenchip.com/2023/10/10/multimodal.html) - att hantera exempelvis text och bild samtidigt
* [Computer vision](https://en.wikipedia.org/wiki/Computer_vision)
* [NLP - Natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing)
* [Paper från Apple om multimodala modeller](https://arxiv.org/abs/2403.09611)
* [Transformerarkitekturen](https://en.wikipedia.org/wiki/Transformer_%28deep_learning_architecture%29) dagens modeller använder
* [Kunskapsgrafer](https://en.wikipedia.org/wiki/Knowledge_graph_embedding)
* [RAG - retrieval augmented generation](https://www.pinecone.io/learn/retrieval-augmented-generation/)
* [ULTRA - modell för grafresonerande](https://github.com/DeepGraphLearning/ULTRA)
* [Perplexity](https://en.wikipedia.org/wiki/Perplexity.ai)
* [Sentimentmodellering](https://en.wikipedia.org/wiki/Sentiment_analysis)
* [Whisper](https://en.wikipedia.org/wiki/Whisper_%28speech_recognition_system%29)
* [Hugging face](https://huggingface.co/)
* [Hugging face introduktion till transformers](https://huggingface.co/docs/transformers/en/index)
* [Agenter](https://en.wikipedia.org/wiki/Software_agent)
* [Microsoft snackade agenter på nittiotalet](https://en.wikipedia.org/wiki/Microsoft_Agent)
* [Langchain](https://www.langchain.com/)
* [Langchain-agenter](https://python.langchain.com/docs/modules/agents/)
* [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning)
* [Crewai](https://www.crewai.com/) - skapar agenter med olika personligheter
* [OpenAI:s function calling-API](https://platform.openai.com/docs/guides/function-calling)
* [Claude - agent-XML-funktioner](https://docs.anthropic.com/claude/docs/functions-external-tools)
* [Claude 3](https://www.anthropic.com/news/claude-3-family)
* [Reasoning](https://en.wikipedia.org/wiki/Reasoning_system)
* [MINDACT](https://arxiv.org/pdf/2306.06070.pdf)
* [Aktiv inferens och Free engery principle](https://en.m.wikipedia.org/wiki/Free_energy_principle)

## Titlar ##
* AI lite mer konkret och framöver
* Vad pågår mer konkret
* Fler parametrar, mer av allt
* Resonera om mer än bara text
* Resonera om hur saker ser ut
* Här är bra, relevant data
* Slumpmässiga tokens från en distribution
* Jag ger dig ett svar på måndag
* Komplexa kunskapssystem
* Någon som jobbar autonomt för ens egen räkning
* Lära en robot öppna en dörr
* Prova handtaget
* Agentstrukturen
* Väldigt mycket kontext
